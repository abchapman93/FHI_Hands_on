{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHI Module 7 Hands-on ---Colon Cancer Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to get your hands dirty\n",
    "\n",
    "You've learned what we need to do and how the tool works. Now it is time for you to make it actually work.\n",
    "\n",
    "You are welcome to spend your time however you'd like but here are a few ideas of how to improve your system:\n",
    "* Improve targets.  Are there any False Negatives your system is missing?  Are there regular expressions that would help?\n",
    "* Improve modifiers.  Not all modifiers typically used in practice are the modifiers starter file.  Are there some to add?  Do some existing modifiers cause problems in your processing?  They can be changed or removed.\n",
    "* Improve document classification rules.  This is **optional**, because the default rules are ready to go. If you are interested, feel free the read the comments in the file to see how it works.\n",
    "\n",
    "\n",
    "## 1. Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages that we will need\n",
    "from nlp_pneumonia_utils import read_doc_annotations\n",
    "from DocumentClassifier import DocumentClassifier\n",
    "from nlp_pneumonia_utils import list_errors\n",
    "from visual import Vis\n",
    "from visual import snippets_markup\n",
    "from visual import view_pycontext_output\n",
    "from visual import display_doc_text\n",
    "# packages for interaction\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_doc_type='FAM_COLON_CA_DOC'\n",
    "annotated_doc_map = read_doc_annotations(archive_file='data/cc_train.zip', pos_type=pos_doc_type)\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_doc_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read in our Knowledge Base files\n",
    "**The targets file is seeded with one target: \"colon cancer\" and \"colon carcinoma\"**  ([target rule file](/edit/KB/fam_cc_targets.yml))  \n",
    "**The modifier file has all modifiers available with pyConText distribution, but the family history modifiers are not complete** ([modifier rule file](/edit/KB/fam_cc_modifiers.yml)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS_FILE_PATH = 'KB/fam_cc_targets.yml'\n",
    "MODIFIERS_FILE_PATH = 'KB/fam_cc_modifiers.yml'\n",
    "FEATURE_INFERENCER_FILE_PATH = 'KB/fam_cc_featurer_inferences.csv'\n",
    "DOC_INFERENCER_FILE_PATH = 'KB/fam_cc_doc_inferences.csv'\n",
    "# clear just in case files/regular expressions have been updated\n",
    "classifier = DocumentClassifier(TARGETS_FILE_PATH, MODIFIERS_FILE_PATH,\n",
    "                               FEATURE_INFERENCER_FILE_PATH, DOC_INFERENCER_FILE_PATH,\n",
    "                               {pos_doc_type})\n",
    "classifier.reset_saved_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's classify some documents\n",
    "The function * list_errors* wraps up several functions together. It will compare the classifier's conclusions against the reference standard (manually annotated documents), and return the false positive documents (with pyConText markups), false negative documents (with manual annotations), and the measurements (precision, recall and F1).\n",
    "\n",
    "\n",
    "For the detailed implementation of this *list_errors* function, you can check the code in [nlp_pneumonia_utils](/edit/nlp_pneumonia_utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('****************')\n",
    "print('Performance for Classifier :')\n",
    "current_false_negatives, current_false_positives, measurements,confusion_matrix_df = classifier.eval(annotated_doc_map)\n",
    "print(measurements)\n",
    "display(confusion_matrix_df)\n",
    "print('****************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Development of your system:\n",
    "* We have found the tools below for highlighting and graphing False Positives and False Negatives to be very useful.  We've provided them below in case it helps you as well\n",
    "\n",
    "Instructions:\n",
    "1. run the system and calculate performance\n",
    "2. review false negatives and positives and make changes to the target file or the modifier file\n",
    "3. repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Review the False Negatives - we have provided two viewers below\n",
    "\n",
    "There are two reasons that our pipeline got false negative errors:\n",
    "\n",
    "1. We don't have the lexicon in your target file. If so, we need to add your new lexicon to [target rule file](/edit/KB/fam_cc_targets.yml)\n",
    "2. Our context rule didn't identify the **family context**, you will need to add it to [modifier rule file](/edit/KB/fam_cc_modifiers.yml)\n",
    "3. Our context rule **excluded** the target concept. If so, we will need to locate the context rule, remove or modifiy it in your [modifier rule file](/edit/KB/fam_cc_modifiers.yml)\n",
    "\n",
    "## False Negative Viewer - reference standard snippet annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_docs=dict((k, v) for k, v in annotated_doc_map.items() if k in current_false_negatives)\n",
    "display(HTML(snippets_markup(fn_docs,'FAM_COLON_CA')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are sure the target lexicon have been included in the targets file, then these false negatives errors must be caused by your modifiers that excluded these targets.Let's take a look at what pyConText output looks like:\n",
    "\n",
    "## False Negative Viewer - pyConText annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the visualizer for pyConText output\n",
    "vis=Vis(MODIFIERS_FILE_PATH)\n",
    "fn_docs = dict((k,v) for k, v in classifier.saved_markups_map.items() if k in current_false_negatives)\n",
    "view_pycontext_output(fn_docs,vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Review the false positives\n",
    "For False Positives, it's most useful to see a pyConText graph since there may need to be modifiers adjusted so that targets can be properly utilized in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_docs = dict((k,v) for k, v in classifier.saved_markups_map.items() if k in current_false_positives)\n",
    "view_pycontext_output(fp_docs,vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.3 pyConText playground\n",
    "After you change your target and modifier rules, type a sentence below (str) and make sure the rule does what you think it does. \n",
    "(move above viewers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh the classifier with updated rules\n",
    "classifier = DocumentClassifier(TARGETS_FILE_PATH, MODIFIERS_FILE_PATH,\n",
    "                               FEATURE_INFERENCER_FILE_PATH, DOC_INFERENCER_FILE_PATH,\n",
    "                               {pos_doc_type})\n",
    "\n",
    "str='''Maternal great aunt with colon cancer Mother died last year of dementia'''\n",
    "res=classifier.predict(str)\n",
    "print(\"Positive\" if res==1 else \"Negative\")\n",
    "view_pycontext_output(classifier.get_last_doc_markups(), vis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Set Evaluation \n",
    "* We've been waiting for the test set.  It will not be available until the morning of the final class session.\n",
    "* At that time, you can uncomment this code and make any changes to it as instructed by the class instructors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_doc_map = read_doc_annotations(archive_file='img/cc_test.zip', pos_type=pos_doc_type)\n",
    "print('****************')\n",
    "print('Performance for Classifier on test set:')\n",
    "current_false_negatives, current_false_positives, measurements,confusion_matrix_df = classifier.eval(annotated_doc_map)\n",
    "print(measurements)\n",
    "display(confusion_matrix_df)\n",
    "print('****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><hr/>This material presented as part of the Foundations of Healthcare Informatics Course, 2017 Fall, BMI, University of Utah. It's revised from the <a href=\"https://github.com/UUDeCART/decart_rule_based_nlp\">material</a> of the DeCART  Summer Program (Data, exploration, Computation, and Analytics Real-world Training for the Health Sciences) at the University of Utah in 2017. <br/><br/>Original presenters : Dr. Wendy Chapman, Jianlin Shi and Kelly Peterson.<br/>\n",
    "Revised by: Jianlin Shi and Dr. Wendy Chapman<br/>\n",
    "<img align=\"left\" src=\"https://wiki.creativecommons.org/images/1/10/Cc.org_cc_by_license.jpg\" alt=\"Except where otherwise noted, this website is licensed under a Creative Commons Attribution 3.0 Unported License.\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {
    "b54463f95d6e47769edf89fccb45bcba": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "e7b8cfbb5bf849148d866cf14ea88a1e": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
